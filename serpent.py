import streamlit as st
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.neighbors import KNeighborsRegressor
from sklearn.model_selection import train_test_split
import joblib

# titre du site
st.set_page_config(layout='wide', page_icon="https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Green_co2_logo2.png?raw=true")
col1, col2, col3 = st.columns([1, 10, 1])
col2.title(":blue[Etude sur les Ã©missions de COâ‚‚ des vÃ©hicules particuliers]")

# menu gauche de navigation
# st.sidebar.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Car_co2_light.png?raw=true", use_column_width=True)
st.sidebar.image("streamlit_assets/Cine_cars_vintage.jpg", use_column_width=True)
st.sidebar.title("Sommaire")
# accÃ¨s aux pages du site
pages=["1 - Analyse exploratoire ", "2 - Data Preparation", "3 - ModÃ©lisation", "4 - Conclusion"]
page=st.sidebar.radio("Aller vers la page :", pages)

# # chargement des donnÃ©es et entraÃ®nement aux modÃ¨les
# # Chargement du dataset
# df = pd.read_csv('https://raw.githubusercontent.com/mogdan/Datascientest_CO2/refs/heads/main/streamlit_assets/Dataset_Rendu2_cleaned.csv', sep=',')

# # Liste des colonnes catÃ©gorielles
# col_cat = ['Type_approval_number', 'Type', 'Variant', 'Make', 'Commercial_name', 'Category_vehicle_type_approved', 'Fuel_mode', 'Fuel_type'] 

# # Application de l'encodage frÃ©quentiel pour chaque colonne catÃ©gorielle
# for col in col_cat:
#   freq_encoding = df[col].value_counts() / len(df)
#   df[col] = df[col].map(freq_encoding)

# # SÃ©lection des variables explicatives (X) et de la variable cible (Y)
# Y = df['CO2_Emissions']
# X = df.drop(['CO2_Emissions'], axis=1)

# # Standardisation des donnÃ©es
# scaler = StandardScaler()
# X_norm = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# # Clustering avec KMeans (optionnel, pour clustering visuel)
# kmeans_model = KMeans(n_clusters=5, random_state=42)
# X_norm['cluster'] = kmeans_model.fit_predict(X_norm)

# # RÃ©duction dimensionnelle avec PCA
# pca = PCA(n_components=2)
# principalComponents = pca.fit_transform(X_norm.drop('cluster', axis=1))

# # Combinaison PCA et KMeans dans un DataFrame
# X_combined = pd.DataFrame(data=principalComponents, columns=['Component 1', 'Component 2'])
# X_combined['Cluster'] = X_norm['cluster']

# # Division en ensembles d'entraÃ®nement et de test
# X_train, X_test, Y_train, Y_test = train_test_split(X_combined[['Component 1', 'Component 2']], Y, test_size=0.2, random_state=42)

# # EntraÃ®nement du modÃ¨le KNN
# knn = KNeighborsRegressor(n_neighbors=4)
# knn.fit(X_train, Y_train)

# # Sauvegarde du modÃ¨le KNN et PCA avec joblib
# joblib.dump(knn, 'model_knn.joblib')
# joblib.dump(scaler, 'scaler.joblib')
# joblib.dump(pca, 'pca.joblib')

# contenu des pages sÃ©lectionnÃ©es
if page == pages[0]: 
  st.header('1 - Exploration des datasets', divider=True)
  st.markdown("# :grey[Prise en main du sujet]")

  with st.expander("ProblÃ©matique"):
    problematique = '''
    :green[Lâ€™**accumulation de gaz Ã  effet de serre**] dans lâ€™atmosphÃ¨re est lâ€™une des principales causes de rÃ©chauffement climatique. 
    
    Or, les transports, et principalement la voiture, sont la premiÃ¨re source de gaz Ã  effet de serre en France.
    Selon l'ADEME, les FranÃ§ais affectionne particuliÃ¨rement ce mode de transport Ã  **77%** malgrÃ© l'attractivitÃ© des autres modes de transports.

    En tant que FranÃ§ais, La voiture est donc responsable dâ€™une part importante de notre empreinte carbone au quotidienn. 
    
    Face Ã  lâ€™urgence climatique, certains constructeurs ont dÃ©jÃ  Å“uvrÃ© ces dix derniÃ¨res annÃ©es sur :
    - lâ€™amÃ©lioration des rendements des moteurs thermiques
    - lâ€™aÃ©rodynamisme
    - lâ€™allÃ¨gement des voitures 

    IntÃ©ressÃ©s par cette problÃ©matique, nous avons ainsi choisi ce sujet pour mettre Ã  profit nos nouvelles compÃ©tences en tant que Data Analyst. 

    Les objectifs pour notre Ã©quipe sur ce sujet sont les suivants :
    -	:green[**Consolider les donnÃ©es dâ€™Ã©tude**] : Rechercher, analyser et nettoyer les donnÃ©es Ã  notre disposition sur ce sujet
    -	:green[**Concevoir un modÃ¨le de prÃ©diction**] :  pour dÃ©terminer les Ã©missions de CO2 en fonction des caractÃ©ristiques des vÃ©hicules
  
    '''
    st.markdown(problematique)

  with st.expander("Sources des DonnÃ©es"):
      ademe = '''
      **[Source ADEME](https://www.data.gouv.fr/fr/datasets/emissions-de-co2-et-de-polluants-des-vehicules-commercialises-en-france/)**  
      - DonnÃ©es franÃ§aises
      - DonnÃ©es allant de 2002 jusquâ€™Ã  2015
      - 300K donnÃ©es
      '''
      st.markdown(ademe)

      ue = '''
      **[Source UE](https://www.eea.europa.ea/data-and-maps/data/co2-cars-emission-20)**  
      - DonnÃ©es europÃ©ennes (dont donnÃ©es franÃ§aises)
      - DonnÃ©es allant de 2010 Ã  2022
      - 80M donnÃ©es
      '''
      st.markdown(ue)

  st.markdown("# :grey[Exploration des donnÃ©es]")

  with st.expander("DonnÃ©es ADEME"):      
        st.markdown("Lâ€˜illustration suivante permet de se rendre compte de la qualitÃ© macro des donnÃ©es ADEME :")
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/ademe_raw.png?raw=true", use_column_width=True)

        ademe_choice = '''
        Pour chaque fichier est indiquÃ© :
        -	Le nb de lignes
        -	Le nb / titres des colonnes

        Notre analyse est alors la suivante :
        -	**Niveau cohÃ©rence** : disparitÃ©s fortes au niveau du format des donnÃ©es
        -	**Niveau complÃ©tude** : pour certaines annÃ©es il manque de la donnÃ©e (2004). Il y a Ã©galement des trÃ¨s fortes disparitÃ©s du nombre dâ€™entrÃ©es entre les annÃ©es

        '''
        st.markdown(ademe_choice)

  with st.expander("DonnÃ©es UE"):      
        st.markdown("Au niveau des donnÃ©es UE, nous constatons rapidement que nous sommes sur un set de donnÃ©es dÃ©jÃ  standardisÃ©es sur le pÃ©rimÃ¨tre europÃ©en de 2010 Ã  2023. ")
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/ue_raw.png?raw=true", use_column_width="auto")
        
        ue_choice = '''
        Notre analyse est alors la suivante :
        -	**Niveau cohÃ©rence** : les donnÃ©es sont dÃ©jÃ  standardisÃ©es dans un mÃªme format
        -	**Niveau complÃ©tude** : il y a Ã©galement sur ce set de donnÃ©es des Ã©carts importants sur les enregistrements entre certaines annÃ©es
        -	**Niveau actualitÃ©** : ces donnÃ©es semblent Ãªtre Ã  jour
        '''
        st.markdown(ue_choice)

  with st.expander("Variables"):      
        st.markdown("Pour commencer le travail exploratoire, nous avons dÃ©cidÃ© de faire un heatmap pour regarder les corrÃ©lations entre les valeurs numÃ©riques. Pou_r se faire, nous avons choisi de remplacer les NaN par la moyenne dans chaque variable.")
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Heatmap.png?raw=true", use_column_width="auto")
        
        corr_model = '''
        Sur ce graphique, 3 corrÃ©lations supÃ©rieures Ã  80% peuvent Ãªtre observÃ©es :
        -	**Mt avec m (kg)** : ces 2 variables reprÃ©sentent le poids des vÃ©hicules. Il est donc logique quâ€™elles soient corrÃ©lÃ©es.
        -	**Enedc (g/km) avec Ewltp (g/km)** : Ces 2 variables reprÃ©sentent les Ã©missions de CO2 calculÃ©es avec des normes diffÃ©rentes. Il y a forte corrÃ©lation entre les deux ce quâ€™il sâ€™avÃ¨re plutÃ´t logique.
        -	**M (kg) avec At2 (mm)** : La variable At2 reprÃ©sente la distance entre les 2 roues AV ou AR dâ€™un vÃ©hicule, tout comme lâ€™At1 dâ€™ailleurs. AprÃ¨s une rapide analyse, on remarque que la variable At2 avait plus de NaN que sa consÅ“ur et que notre remplacement par la moyenne ait pu avoir des effets de bord.
        '''
        st.markdown(corr_model)

  with st.expander("CritÃ¨res ENEDC / EWLTP"):  
        critere = '''
        Ce sont 2 indicateurs de mesure des Ã©missions de CO2 : 
        -	**NEDC** signifiant Â« New European Driving Cycle Â» ou Â« Nouveau Cycle de Conduite EuropÃ©en Â», câ€™est une norme dâ€™homologation des vÃ©hicules neufs introduite en 1997 en Europe et qui a eu cours jusqu'en septembre 2017. La norme va dÃ©finir les conditions dans lesquelles un modÃ¨le est testÃ©, allant de la vitesse Ã  la tempÃ©rature, avec un avantage : tous les vÃ©hicules suivent le mÃªme protocole.
        -	**WLTP** (Worldwide Harmonized Light Vehicles Test Procedure) pour tout nouveau modÃ¨le Ã  partir du 1er septembre 2017. Il concerne tous les vÃ©hicules neufs au 1er septembre 2018, et jusquâ€™aux vÃ©hicules en stock homologuÃ©s NEDC et vendus aprÃ¨s le 1er septembre 2019.
        '''
        st.markdown(critere)
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Comparaison ENEDC-EWLTP par an.png?raw=true", use_column_width="auto")
        
        critere1 = '''
        GrÃ¢ce Ã  cette analyse, c'est Ã  cette Ã©tape que nous avons choisi d'exclure les annÃ©es 2015 et 2016 dans la suite de notre Ã©tude Ã  cause du faible nombre de donnÃ©es.
        
        :green[Sur les autres annÃ©es, notre analyse a Ã©tÃ© la suivante :]
        -	En 2017 et 2018, nous avons des donnÃ©es ENEDC et peu voire pas de donnÃ©es EWLTP
        -	Durant la pÃ©riode 2019 â€“ 2020, il y a coexistence des donnÃ©es sur ces 2 types de mesures.
        -	En revanche cette tendance qui sâ€™inverse Ã  partir 2021 oÃ¹ les donnÃ©es ENEDC sont majoritairement absentes.

        Pour pousser notre analyse d'un cran supplÃ©mentaire, nous nous sommes concentrÃ©s sur l'annÃ©e 2020 oÃ¹ nous avons des donnÃ©es complÃ¨tes sur les 2 critÃ¨res. 
        '''

        st.markdown(critere1)
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Boxplot - comparasion 2020 ENEDC-EWLTP.png?raw=true", use_column_width="auto")
        critere2 = '''
        Ce que nous avons voulu mettre en Ã©vidence ici est la mÃ©diane des Ã©missions par type de carburant et par norme (Enedc puis Ewltp), et la diffÃ©rence par type de carburant.

        :green[**Conclusion** : 
        - GrÃ¢ce Ã  ce graphique, npous pouvons confirmer que les Ã©missions calculÃ©es avec la norme NEDC sont plus faibles quâ€™avec la norme WLTP.
        - Nous pouvons tenter de reconstruire des donnes proches des donnÃ©es EWLTP sur les annÃ©es oÃ¹ ce rÃ©fÃ©rentiel n'Ã©tait pas en application]

        '''
        st.markdown(critere2)

  with st.expander("Approfondissements"):  
        distrib = '''
        Pour continuer notre travail exploratoire, nous avons regardÃ© le nombre de vÃ©hicules par type de carburant sur ce jeu de donnÃ©es.
        '''
        st.markdown(distrib)
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Nb vÃ©hicules par type de carburant.png?raw=true", use_column_width="auto")
        
        distrib1 = '''
        :green[**Nous observons ainsi une grande prÃ©dominance des voitures Essence et Diesel dans nos donnÃ©es.**]
        
        Pour complÃ©ter ce graphique, il nous a semblÃ© intÃ©ressant dâ€™observer **lâ€™Ã©volution dans le temps pour chaque carburant** :
        '''
        st.markdown(distrib1)
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Nb vÃ©hicules par type de carburant et par an.png?raw=true", use_column_width="auto")
        distrib2 = '''
        
        :green[**Nous observons une diminution progressive des immatriculations pour les voitures Essence / Diesel** ces derniÃ¨res annÃ©es et une augmentation progressive des voitures Ã©lectriques Ã  partir de 2019. 
        Cependant, ces graphiques ne permettent pas dâ€™observer de causes conjoncturelles ou structurelles pour ces tendances.]

        Pour aller plus loin, on s'est intÃ©ressÃ© Ã  la distribution par type de carburant et la taille de cylindrÃ©e pour voir comment sont rÃ©partis les vÃ©hicules.
        
        '''
        st.markdown(distrib2)
        st.image("https://github.com/mogdan/Datascientest_CO2/blob/main/streamlit_assets/Distribution par type de carburant et taille de cylindrÃ©e.png?raw=true", use_column_width="auto")
        
        distrib3 = '''
        Nous pouvons voir pour les catÃ©gories qui nous intÃ©ressent :
        -	**Essence :** Les vÃ©hicules essences sont en gÃ©nÃ©ral bien Ã©quilibrÃ©es dans leur rÃ©partition, la moyenne se situant quasi au mÃªme niveau que la mÃ©diane. Il y a toutefois une large dispersion de VA (grosses cylindrÃ©es â€“ ex. sport, luxe)
        -	**Diesel :** la cylindrÃ©e est en gÃ©nÃ©ral plus importante que pour lâ€™homologue en version essence et possÃ¨de une dispersion plus faible de valeurs aberrantes.
        '''
        st.markdown(distrib3)


  st.markdown("# :grey[Conclusion de l'Analyse Exploratoire]")

  with st.expander("Choix des donnÃ©es"):      
        st.markdown("Au vu des problÃ©matiques vues prÃ©cÃ©demment sur les donnÃ©es ADEME, nous avons dÃ©cidÃ© de nous concentrer sur les :green[**donnÃ©es UE.**] ")
  
  with st.expander("Choix de la pÃ©riode d'observation"):      
        period_choice = '''
        :green[**Cette Ã©tape a pour enjeu de nous permettre de sÃ©lectionner la plage de donnÃ©es sur laquelle va sâ€™appuyer notre modÃ¨le.**]
        
        Pour notre Ã©tude, nous avons choisi la pÃ©riode Â« 2017 â€“ 2022 Â».
        -	Avant 2017, nous n'avions pas beaucoup de donnÃ©es
        -	Le faible volume de donnÃ©es 2023 traduit des donnÃ©es non encore intÃ©grÃ©es (annÃ©e en cours)
        '''
        st.markdown(period_choice)

elif page == pages[1]:
  st.header('2 - Nettoyage et sÃ©lection des donnÃ©es', divider=True)

  with st.expander("Etapes de transformation"):  
   st.markdown('''
               Voici, en rÃ©sumÃ©, quelles Ã©tapes nous allons procÃ©der afin de prÃ©parer les donnÃ©es Ã  la modÃ©lisation : 
               -	Conserver les donnÃ©es entre 2017 et 2022
               -	Conserver les donnÃ©es FR
               -  Conserver les vÃ©hicules avec Ã©nergies carbonnÃ©es
               -	Conserver les champs suivants : 'Tan', 'T', 'Va', 'Mk', 'Cn', 'Ct', 'm (kg)', 'Enedc (g/km)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'Ft', 'Fm', 'ec (cm3)', 'ep (KW)', 'year'
               -	Standardiser la variable 'Mk' (constructeur)
               -	Standardiser la variable 'Ft' (carburant)
               -  Supprimer les doublons
                -	CrÃ©er une nouvelle variable 'CO2_Emission' sur la base de 'enedc', 'ewltp' et 'median'
               -	Supprimer les variables ayant permis de construire CO2_Emission
               -  Traitement des NaN
               -	Renommer les titres de colonne pour faciliter la manipulation des donnÃ©es
               ''')
   
  st.markdown("# :grey[RÃ©duction des variables]")
   
  with st.expander("Variable Year"):
   st.markdown("Comme expliquÃ© dans l'analyse exploratoire, :green[**nous devons garder seulement les donnÃ©es entre 2017 et 2022**]")
   st.code("df=df[(df.year>2016) & (df['year']<2023)]")           

  with st.expander("Variables Country"):
   st.markdown("Nous avons fait le choix pour cette Ã©tude de garder seulement :green[**les vÃ©hicules immatriculÃ©s en France**]")
   st.code("df=df[(df['Country']=='FR')]")     

  with st.expander("Variables Fuel type (ft)"):
   st.markdown("Les vÃ©hicules Ã©lectriques ou avec un moteur Ã  hydrogÃ¨ne ne dÃ©gageant pas d'Ã©missions de CO2, nous les avons exclus du modÃ¨le")
   st.code( '''
            df = df[df['Ft'] != 'ELECTRIC']
            df = df[df['Ft'] != 'HYDROGEN']
            ''')       
   
  with st.expander("Conservation des variables essentielles"):
   st.markdown("Le but de notre Ã©tude est de montrer les caractÃ©ristiques moteurs Ã©mettant du CO2. Nous avons gardÃ© seulement les champs pertinents, qui ont peu de NaN")
   st.markdown('''De plus, une colonne ID est prÃ©sente dans les donnÃ©es de base, variable que nous avons dÃ©cidÃ© de supprimer, car nous n'analyserons pas le nombre de vÃ©hicules par type de carburant.
               Cela prÃ©sentera un avantage non nÃ©gligeable : :green[**une rÃ©duction drastique du volume de donnÃ©es**]''')
   st.code( '''
            values_to_keep=['Tan', 'T', 'Va', 'Mk', 'Cn', 'Ct', 'm (kg)', 'Enedc (g/km)', 'Ewltp (g/km)', 'W (mm)', 'At1 (mm)', 'Ft', 'Fm', 'ec (cm3)', 'ep (KW)', 'year']
            df=df[values_to_keep]
            ''')       
  st.markdown("# :grey[Standardisation des variables]")
  with st.expander("Variable Constructeur (Mk)"):
   st.markdown("Beaucoup de champs n'Ã©tant pas propres sur cette variable, il a fallu nettoyer les donnÃ©es.")
   st.code( '''
            df['Mk']= df['Mk'].astype(str)
            df['Mk']= df['Mk'].apply(lambda x : x.upper())
            df['Mk'].replace({  'ALPINA':'BMW',
                    'BMW I':'BMW',
                    'QUATTRO' : 'AUDI',
                    'PÃƒâ€“SSL' :'PÃ–SSL',
                    'P?SSL' : 'PÃ–SSL',
                    'ROLLS ROYCE' : 'ROLLS-ROYCE',
                    'VOLKSWAGEN, VW' : 'VOLKSWAGEN',
                    'MITSUBISHI MOTORS (THAILAND)' : 'MITSUBISHI',
                    'MERCEDES-AMG' : 'MERCEDES AMG',
                    'MERCEDES-BENZ' : 'MERCEDES BENZ',
                    'MC LAREN' : 'MCLAREN',
                    'FORD-CNG-TECHNIK' : 'FORD',
                    'MERCEDES AMG' : 'MERCEDES BENZ',
                    'HYUNDAI                                           ': 'HYUNDAI',
                    'RENAULT TECH' : 'RENAULT'
                 }, inplace=True)
            ''')       
  with st.expander("Variable Fuel type (ft)"):
   st.markdown("Idem pour cette variable.")
   st.code( '''
            df['Ft']= df['Ft'].astype(str)
            df['Ft']= df['Ft'].apply(lambda x : x.upper())
            df['Ft'].replace({'DIESEL-ELECTRIC':'DIESEL/ELECTRIC',
            'UNKNOWN':np.nan,
            'PETROL-ELECTRIC':'PETROL/ELECTRIC', 'NAN':np.nan}, inplace=True)
            ''')       
   
  st.markdown("# :grey[Suppression des doublons]")
  with st.expander("Traitement"):
   st.code( '''
            print("Nombre de lignes AVANT traitement :", len(df))
            print("doublons AVANT traitement: ",df.duplicated().sum())
            df.drop_duplicates(inplace= True)
            print("doublons APRES traitement: ",df.duplicated().sum())
            print("Nombre de lignes APRES traitement :", len(df))
           ''')
   st.markdown('''
              Voici le rÃ©sultat :
              - Nombre de lignes AVANT traitement : 11463387
              - doublons AVANT traitement:  11232814
              - doublons APRES traitement:  0
              - Nombre de lignes APRES traitement : 230573
               ''')

  st.markdown("# :grey[CrÃ©ation de la variable CO2_Emission]")
  with st.expander("Calcul des mÃ©dianes pour chaque type de carburant Ã  partir de 'Enedc (g/km)' et 'Ewltp (g/km)'"):
    st.code( '''
            medians_enedc = df.groupby('Ft')['Enedc (g/km)'].median()
            medians_ewltp = df.groupby('Ft')['Ewltp (g/km)'].median()
           ''')
  with st.expander("Fonction pour calculer CO2_Emission"):
    st.markdown('CrÃ©ation de la fonction :')
    st.code( '''
            def calculate_emissions(row):
              if not np.isnan(row['Ewltp (g/km)']):
                return row['Ewltp (g/km)']
              else:
                fuel_type = row['Ft']
                median_enedc = medians_enedc.get(fuel_type, 0)
                median_ewltp = medians_ewltp.get(fuel_type, 0)
                adjustment = median_enedc - median_ewltp
                return row['Enedc (g/km)'] - adjustment
           ''') 
    st.markdown('Avec sa mise en application sur les donnÃ©es')
    st.code('''df['CO2_Emissions'] = df.apply(calculate_emissions, axis=1)''')

    st.markdown('''Suppression des colonnes d'origine''')
    st.code('''df=df.drop(['Enedc (g/km)', 'Ewltp (g/km)'],axis=1)''')

  st.markdown("# :grey[Traitement des NaN]")
  with st.expander("Choix du traitement"):
    st.markdown('''
                Nous avons calculÃ© Ã  cette Ã©tape le nombre de NaN dans les donnÃ©es restantes, voici le rÃ©sultat :
                ''')
    st.code('''
            print("Somme des valeurs manquantes :",df.isna().sum().sum())
            Somme des valeurs manquantes : 354
            ''')
    st.markdown("Ce rÃ©sultat reprÃ©sente 0,15% des donnÃ©es de notre modÃ¨le, nous supprimons ces donnÃ©es.")
                
    st.code('''
            df = df.dropna(axis = 0, how = 'any')
            print('Taille aprÃ¨s dropna :', len(df))
            ''')
    st.markdown('''Il reste 230336 entrÃ©es post nettoyage. Lâ€™entraÃ®nement sur les diffÃ©rents modÃ¨les peut alors Ãªtre rÃ©alisÃ©.''')

  st.markdown("# :grey[Renommage des variables]")
  with st.expander("Vers plus de clartÃ©"):
     st.code('''
             Colname_mapping = {'Tan': 'Type_approval_number',
                   'T': 'Type',
                   'Va': 'Variant',
                   'Mk': 'Make',
                   'Cn': 'Commercial_name',
                   'Ct': 'Category_vehicle_type_approved',
                   'm (kg)': 'Mass_kg',
                   'W (mm)': 'Wheel_Base_(length_mm)',
                   'At1 (mm)': 'Track_(width_mm)',
                   'Ft': 'Fuel_type',
                   'Fm': 'Fuel_mode',
                   'ec (cm3)': 'Engine_capacity_cm3',
                   'ep (KW)': 'Engine_power_KW',
                   'year': 'Reporting_year'}

                    df.rename(columns=Colname_mapping, inplace=True)

             ''')

elif page == pages[2]:
  st.header('3 - ModÃ©lisation', divider=True)

  st.markdown("# :grey[MÃ©thodologie]")
  st.markdown("Nous cherchons Ã  prÃ©dire des valeurs continues d'Ã©missions de CO2 et nous allons donc utiliser des modÃ¨les de **rÃ©gression**")
  st.markdown("Nous avons sÃ©lectionnÃ© les modÃ¨les suivants :")
  with st.expander("Gradient Boosting Regressor", icon='ğŸ”²'):
    "#### GradientBoostingRegressor"
    "Score sur train : 0.9246557461016944"
    "Score sur test : 0.9267762036497856"
    "On affiche le graphe de feature importance :"
    st.image('streamlit_assets/Feature importance GradientBoost.png')

    "#### XGBoost"
    "Score sur train : 0.9784847196200369"
    "Score sur test : 0.9762445538965321"
    "On affiche le graphe de feature importance :"
    st.image('streamlit_assets/Feat_Imp_XGBoost.png')
    "Le modÃ¨le XGBoost obtient de meilleurs scores mais repose quasi totalement sur la variable Fuel_type"
    "**Pour les 2 modÃ¨les les scores sur le jeu dâ€™entrainement et sur le jeu de test sont trÃ¨s proches ce qui laisse penser quâ€™il nâ€™y a pas dâ€™over-fitting**"
    
  # with st.expander("Linear Regressor", icon='ğŸ”²'):
  #    "Les scores obtenus sont"
  #    "Score sur train : 0.7963421436183908"
  #    "Score sur test : 0.7902289500042596"
  #    "Comme Scikit-learn ne fournit pas directement de features importances, nous avons appliquÃ© la mÃ©thode des coefficients"
  #    st.image('streamlit_assets/Feature importance RegressionLineaire.png')

  with st.expander("Random Forest Regressor", icon='ğŸ”²'):
     "Les scores obtenus sont"
     "- Score sur train : 0.9941824620769759"
     "- Score sur test : 0.9879863516148067"
     "On calcule la MSE et RMSE"
     "- MSE: 8.783648647914177"
     "- RMSE: 2.9637220935698707"
     "Ici, cela signifie que le modÃ¨le fait, en moyenne, une erreur de prÃ©diction de 2,96 g/km de CO2"
     "On affiche le graphe de feature importance"
     st.image('streamlit_assets/Feature importance RandomForest.png')
     "on peut voir que le type de carburant et la puissance du moteur sont les 2 variables principalement utilisÃ©es pour la prÃ©diction (66% Ã  elles 2)"
     "Le poids et la cylindrÃ©e sont les suivantes (environ 25% Ã  elles 2)"
  
elif page == pages[3]:
  st.header('4 - Conclusion', divider=True)
  st.markdown("""
              Pour conclure notre Ã©tude sur les Ã©mission de CO2 des vÃ©hicules, plusieurs points clÃ©s Ã©mergent:
              - **DonnÃ©es limitÃ©es** : Nous avons exploitÃ© les donnÃ©es disponibles depuis 2015, mais leur recul est restreint.
              - **SurreprÃ©sentation des vÃ©hicules thermiques** : Notre jeu de donnÃ©es est largement composÃ© de vehicules essence et diesel, ce qui reflÃ¨te la forte prÃ©sence de ces motorisation sur les routes.
              - **Variables influentes pour le rejet de CO2** : Le dimensionnement du vÃ©hicule (poids, taille de la cylindrÃ©e) et les spÃ©cifications du moteur se sont avÃ©rÃ©s plus significatifs pour prÃ©dire les Ã©missions de CO2.
  """)
  st.subheader("Tableau des Perspectives d'AmÃ©lioration")
  # CrÃ©er les colonnes pour structurer le tableau
  col1, col2 = st.columns([1, 2])
  # Ajouter le contenu dans chaque colonne
  with col1:
    st.subheader("Domaine")
    st.write("1. Standardisation des mesures")
    st.write("2. ModÃ¨les d'apprentissage")
    st.write("3. Ã‰tude sur les conditions")
  with col2:
    st.subheader("Piste d'amÃ©lioration")
    st.write("1. Uniformiser les donnÃ©es d'Ã©mission de COâ‚‚ pour toutes les marques, y compris les vÃ©hicules plus rÃ©cents.")
    st.write("2. Utiliser des modÃ¨les avancÃ©s avec optimisation des hyperparamÃ¨tres pour amÃ©liorer la prÃ©cision.")
    st.write("3. IntÃ©grer des donnÃ©es sur les conditions de circulation (rurale, urbaine, mixte) pour affiner les prÃ©dictions.")
 
  st.divider()

  import streamlit as st
  import pandas as pd
  import numpy as np
  import joblib
  from sklearn.ensemble import RandomForestRegressor
  from sklearn.model_selection import train_test_split
  from sklearn.preprocessing import StandardScaler, RobustScaler
  from sklearn.metrics import f1_score
  from xgboost import XGBRegressor

  # Chargement du dataset
  df = pd.read_csv('https://raw.githubusercontent.com/mogdan/Datascientest_CO2/refs/heads/main/streamlit_assets/Dataset_Rendu2_cleaned.csv', sep=',')

  # SÃ©paration des colonnes numÃ©riques et catÃ©gorielles
  col_num = ['Mass_kg', 'Wheel_Base_(length_mm)', 'Track_(width_mm)', 'Engine_capacity_cm3', 'Engine_power_KW', 'Reporting_year']
  col_cat = ['Type_approval_number', 'Type', 'Variant', 'Make', 'Commercial_name', 'Category_vehicle_type_approved', 'Fuel_mode', 'Fuel_type']

  # Encodage frÃ©quentiel des variables catÃ©gorielles
  def frequency_encoding(df, column):
    frequency = df[column].value_counts()
    df[column + '_encoded'] = df[column].map(frequency)
    return df

  for col in col_cat:
    df = frequency_encoding(df, col)

  # Supprimer les colonnes catÃ©gorielles d'origine
  df = df.drop(col_cat, axis=1)
  col_cat_encoded = [col + '_encoded' for col in col_cat]

  # SÃ©parer les donnÃ©es en train/test
  X = df.drop('CO2_Emissions', axis=1)
  y = df['CO2_Emissions']
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

  # Appliquer le scaling
  scaler = RobustScaler()
  X_train[col_num] = scaler.fit_transform(X_train[col_num])
  # X_test[col_num] = scaler.transform(X_test[col_num])

  # Utiliser StandardScaler pour les variables encodÃ©es
  scaler_cat = StandardScaler()
  X_train[col_cat_encoded] = scaler_cat.fit_transform(X_train[col_cat_encoded])
  # X_test[col_cat_encoded] = scaler_cat.transform(X_test[col_cat_encoded])

  # # EntraÃ®ner le modÃ¨le RandomForest
  # model_rf = RandomForestRegressor()
  # model_rf.fit(X_train, y_train)
  # joblib.dump(model_rf, 'model_rf.joblib')

  # Chargement du modÃ¨le
  model_xgboost = joblib.load('model_XGBoost.joblib')

  # Interface utilisateur
  st.title("Application de calcul des Ã©missions de CO2")
  st.header("Calculateur d'empreinte carbone pour les vÃ©hicules")

  # EntrÃ©es utilisateur
  col1, col2, col3 = st.columns(3)

  with col1:
    weekly_km = st.slider("ğŸ“ Distance moyenne hebdomadaire (en km)", 5, 1000, 200, 5)
    yearly_km = weekly_km * 52

  with col2:
    fuel_type = st.selectbox("â›½ Type de carburant", ["PETROL", "DIESEL", "LPG", "PETROL/ELECTRIC", "DIESEL/ELECTRIC", 'NG', 'E85', 'NG-BIOMETHANE'])

  with col3:
    engine_capacity = st.slider("ğŸï¸ CylindrÃ©e (en litres)", 0.5, 10.0, 1.6, 0.1)

  reporting_year = st.select_slider("ğŸ“… AnnÃ©e d'immatriculation du vÃ©hicule", range(2017, 2023), 2020)

  # Encodage du type de carburant
  fuel_type_freq = df['Fuel_type_encoded'].value_counts() / len(df)
  fuel_type_encoded = fuel_type_freq.get(fuel_type, 0)

  # Bouton de calcul
  if st.button("Calculer les Ã©missions de CO2"):
    # PrÃ©paration des donnÃ©es pour la prÃ©diction
    prediction_input = [reporting_year, engine_capacity, fuel_type_encoded]
    nombre_caracteristiques_attendues = len(X.columns)
    
    if len(prediction_input) < nombre_caracteristiques_attendues:
        prediction_input += [0] * (nombre_caracteristiques_attendues - len(prediction_input))

    prediction_input = np.array(prediction_input).reshape(1, -1)
    
    # Application les transformations pour normaliser les donnÃ©es d'entrÃ©e
    prediction_input[:, :len(col_num)] = scaler.transform(prediction_input[:, :len(col_num)])
    prediction_input[:, len(col_num):] = scaler_cat.transform(prediction_input[:, len(col_num):])

    # PrÃ©diction
    CO2_emission = model_xgboost.predict(prediction_input)[0]
    yearly_emission = CO2_emission * yearly_km / 1000000
    yearly_average = 103 * yearly_km / 1000000

    # Affichage des rÃ©sultats
    st.header("RÃ©sultats")
    st.info(f"Ã‰missions estimÃ©es pour ce vÃ©hicule sur {yearly_km} km annuels : {yearly_emission:.2f} tonnes de CO2")
    st.warning(f"Emissions moyennes en France pour ce mÃªme kilomÃ©trage : {yearly_average:.2f} tonnes de CO2 (ref. : aoÃ»t 2022)")
